numpy==1.26.4
pandas==2.2.2

# accelerate==0.31.0
# transformers==4.41.2
torch==2.3.1

--index-url https://abetlen.github.io/llama-cpp-python/whl/metal
-c CMAKE_ARGS=-DLLAMA_METAL=on
llama-cpp-python
llama-cpp-python[server]

jupyter==1.0.0
ipykernel==6.29.4
ipython==8.25.0
ipywidgets==8.1.3
